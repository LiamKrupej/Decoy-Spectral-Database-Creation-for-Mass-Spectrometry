{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset Cleaned by Matchms and Lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matchms import Scores, Spectrum\n",
    "from matchms.importing import load_from_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.dirname(os.getcwd())\n",
    "#path_data = os.path.join(ROOT, 'data')\n",
    "path_data = 'C:\\\\Users\\\\User\\\\Data'\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "from matchms.importing import load_from_json\n",
    "\n",
    "filename = os.path.join(path_data,'gnps_positive_ionmode_cleaned_by_matchms_and_lookups.json')\n",
    "spectrums = load_from_json(filename)\n",
    "\n",
    "print(\"number of spectra:\", len(spectrums))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting peaks per spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_peaks = [len(spec.peaks) for spec in spectrums]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "hist = plt.hist(number_of_peaks, np.arange(0,2000,20))\n",
    "plt.xlabel(\"number of peaks in spectrum\")\n",
    "plt.ylabel(\"number of spectra in respective bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Process\n",
    "\n",
    "Preparing data for cosine similarity scoring. Done by:\n",
    "\n",
    "- normalize peaks (maximum intensity to 1)\n",
    "- remove peaks outside [0, 1000] m/z window\n",
    "- remove spectra with < 10 peaks\n",
    "- remove peaks with intensities < 0.01 of maximum intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "\n",
    "def post_process(s):\n",
    "    s = normalize_intensities(s)\n",
    "    s = select_by_mz(s, mz_from=0, mz_to=1000)\n",
    "    s = select_by_relative_intensity(s, intensity_from=0.01, intensity_to=1.0)\n",
    "    s = reduce_to_number_of_peaks(s, 10, 150, None)\n",
    "    return s\n",
    "\n",
    "# apply filters to the data\n",
    "spectrums = [post_process(s) for s in spectrums]\n",
    "\n",
    "# omit spectrums that didn't qualify for analysis\n",
    "spectrums = [s for s in spectrums if s is not None]\n",
    "\n",
    "\n",
    "print(\"Remaining spectra after post process\", len(spectrums))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrumsblah = spectrums.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrumswithpeak = []\n",
    "\n",
    "def get_parent_peak(s): \n",
    "    precursor = s.metadata['precursor_mz']  \n",
    "    tolerance = (precursor / 1000000) * 5\n",
    "    condition = (s.peaks.mz >= precursor - tolerance) & (s.peaks.mz <= precursor + tolerance)\n",
    "    mz_candidates = s.peaks.mz[condition]\n",
    "    intensities_candidates = s.peaks.intensities[condition]\n",
    "    if len(mz_candidates) is 0:\n",
    "        return 0\n",
    "    else: \n",
    "        max_index = np.argmax(intensities_candidates)\n",
    "        return mz_candidates[max_index], intensities_candidates[max_index]\n",
    "\n",
    "for spec in spectrums:\n",
    "    if(get_parent_peak(spec) != 0):\n",
    "        spectrumswithpeak.append(spec)\n",
    "    \n",
    "print(len(spectrumswithpeak))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chem_string(spec):\n",
    "    s = spec.metadata['inchi']\n",
    "    if(s == \"\") or (s is None):\n",
    "        return None\n",
    "    else:\n",
    "        string_in_slashes = s.split('/')[1].strip()\n",
    "        return string_in_slashes\n",
    "    \n",
    "def are_peaks_similar(mass1, mass2):\n",
    "    tolerance = 1\n",
    "    if(-1 <= (mass1 - mass2) <= 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_with_inchi = []\n",
    "\n",
    "for spec in spectrumswithpeak:\n",
    "    if(find_chem_string(spec) is not None):\n",
    "        spectrums_with_inchi.append(spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spectrums_with_inchi))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[0]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[1]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[2]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[3]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[4]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[4]))\n",
    "\n",
    "print(find_chem_string(spectrums_with_inchi[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_molecule_here(spec, spec_list):\n",
    "    ishere = 0\n",
    "    mcl = find_chem_string(spec)\n",
    "    print(mcl)\n",
    "    for s in spec_list:\n",
    "        lib_mcl = find_chem_string(s)\n",
    "        if(mcl == lib_mcl) and (are_peaks_similar(spec, s) == True):\n",
    "            ishere = 1\n",
    "    return ishere\n",
    "\n",
    "library_spectrums = []\n",
    "query_spectrums = []\n",
    "\n",
    "for spec in spectrums_with_inchi:    \n",
    "        if(is_molecule_here(spec,library_spectrums) == 0) & (len(library_spectrums) < 3000):\n",
    "            library_spectrums.append(spec)\n",
    "\n",
    "        elif(is_molecule_here(spec,query_spectrums) == 0) & (len(query_spectrums) < 1000):\n",
    "            query_spectrums.append(spec)\n",
    "\n",
    "        print(\"library is \", len(library_spectrums), \"and query is \", len(query_spectrums))\n",
    "  \n",
    "          \n",
    "print(len(library_spectrums))\n",
    "print(len(query_spectrums))\n",
    "\n",
    "\n",
    "molecule_matches = 0\n",
    "for spec in query_spectrums:\n",
    "    if(is_molecule_here(spec, library_spectrums) == True):\n",
    "        molecule_matches += 1\n",
    "\n",
    "print(\"Molecule matches =\", molecule_matches)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_library = library_spectrums.copy()\n",
    "safety_query = query_spectrums.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_inchi_and_precursor(query, library):\n",
    "    queries_with_inchi_match = []\n",
    "    queries_with_precursor_match = []\n",
    "    queries_with_inchi_match_and_precursor = []\n",
    "    \n",
    "    for spec in query:\n",
    "        for s in library:\n",
    "            if(find_chem_string(spec) == find_chem_string(s)):\n",
    "                queries_with_inchi_match.append(spec)          \n",
    "            if(are_peaks_similar(spec.metadata['precursor_mz'], s.metadata['precursor_mz']) == True):\n",
    "                queries_with_precursor_match.append(spec)\n",
    "            if(find_chem_string(spec) == find_chem_string(s)) and ((are_peaks_similar(spec.metadata['precursor_mz'], s.metadata['precursor_mz']) == True)):\n",
    "                    queries_with_inchi_match_and_precursor.append(spec)\n",
    "                    \n",
    "    print(len(queries_with_inchi_match))  \n",
    "    print(len(queries_with_precursor_match))      \n",
    "    print(len(queries_with_inchi_match_and_precursor))      \n",
    "    type_of_match = [\"Inchi_Match\", \"Precurs_Match\", \"Inchi_&_Precurs_Match\"]\n",
    "    num_of_matches= [len(queries_with_inchi_match), len(queries_with_precursor_match), len(queries_with_inchi_match_and_precursor)]\n",
    "                    \n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(type_of_match, num_of_matches)\n",
    "    plt.xlabel(\"number of peaks in spectrum\")\n",
    "    plt.ylabel(\"number of spectra in respective bin\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "look_for_inchi_and_precursor(query_spectrums, library_spectrums)\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_spectrums(list):  \n",
    "\n",
    "    number_of_peaks = [len(spec.peaks) for spec in list]\n",
    "    plt.figure(figsize=(12,7))\n",
    "    hist = plt.hist(number_of_peaks, np.arange(0,2000,20))\n",
    "    plt.xlabel(\"number of peaks in spectrum\")\n",
    "    plt.ylabel(\"number of spectra in respective bin\")\n",
    "    average = 0\n",
    "    min = len(list[0].peaks.mz)\n",
    "    max  = 0\n",
    "    min_spec = None\n",
    "    max_spec = None\n",
    "    print(min)\n",
    "    for spec in list:\n",
    "        average += len(spec.peaks.mz) \n",
    "        if min > len(spec.peaks.mz):\n",
    "            min = len(spec.peaks.mz)\n",
    "            min_spec = spec\n",
    "        if max < len(spec.peaks.mz):\n",
    "            max = len(spec.peaks.mz)\n",
    "            max_spec = spec\n",
    "    average = average / len(list)\n",
    "    print(average)\n",
    "    print(min)\n",
    "    min_spec.plot()\n",
    "    print(max)\n",
    "    max_spec.plot()\n",
    "    \n",
    "analyse_spectrums(library_spectrums)\n",
    "analyse_spectrums(query_spectrums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fragment_peak:\n",
    "    mz = 0\n",
    "    intensity = 0\n",
    "    spectrum_id = \"\"\n",
    "    \n",
    "    def __init__(self, mz, intensity, spectrum_id):\n",
    "        self.mz = mz\n",
    "        self.intensity = intensity\n",
    "        self.spectrum_id = spectrum_id   \n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.mz < other.mz\n",
    "\n",
    "    def _eq_(self, other):\n",
    "        return self.mz == other.mz\n",
    "    \n",
    "    def print_fragment(self):\n",
    "        print(\"Peak with mz: \", self.mz, \", intensity: \", self.intensity, \", from spectrum: \", self.spectrum_id)\n",
    "   \n",
    "    \n",
    "\n",
    "frag1 = fragment_peak(spectrums[3].peaks.mz[1], spectrums[3].peaks.intensities[1], spectrums[3].get('spectrum_id'))\n",
    "frag2 = fragment_peak(spectrums[1].peaks.mz[1], spectrums[1].peaks.intensities[1], spectrums[1].get('spectrum_id'))\n",
    "frag3 = fragment_peak(spectrums[2].peaks.mz[1], spectrums[2].peaks.intensities[1], spectrums[2].get('spectrum_id'))\n",
    "frag4 = fragment_peak(spectrums[5].peaks.mz[1], spectrums[5].peaks.intensities[1], spectrums[5].get('spectrum_id'))\n",
    "frag5 = fragment_peak(spectrums[6].peaks.mz[1], spectrums[6].peaks.intensities[1], spectrums[6].get('spectrum_id'))\n",
    "\n",
    "frag_list = [frag1, frag2, frag3, frag4, frag5]\n",
    "frag_order = [f.mz for f in frag_list]\n",
    "\n",
    "print(frag_order)\n",
    "\n",
    "frag_list_sorted = sorted(frag_list)\n",
    "frag_list_sorted_order = [f.mz for f in frag_list_sorted]\n",
    "\n",
    "print(frag_list_sorted_order)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import operator\n",
    "\n",
    "def index(a, x):\n",
    "    'Locate the leftmost value exactly equal to x'\n",
    "    i = bisect.bisect_left(a, x)\n",
    "    if i != len(a) and a[i] == x:\n",
    "        return i\n",
    "    raise ValueError\n",
    "\n",
    "def find_lt(a, x):\n",
    "    'Find rightmost value less than x'\n",
    "    i = bisect.bisect_left(a, x)\n",
    "    if i:\n",
    "        return a[i-1]\n",
    "    raise ValueError\n",
    "\n",
    "def find_le(a, x):\n",
    "    'Find rightmost value less than or equal to x'\n",
    "    i = bisect.bisect_right(a, x)\n",
    "    if i:\n",
    "        return a[i-1]\n",
    "    raise ValueError\n",
    "\n",
    "def find_gt(a, x):\n",
    "    'Find leftmost value greater than x'\n",
    "    i = bisect.bisect_right(a, x)\n",
    "    if i != len(a):\n",
    "        return a[i]\n",
    "    raise ValueError\n",
    "\n",
    "def find_ge(a, x):\n",
    "    'Find leftmost item greater than or equal to x'\n",
    "    i = bisect.bisect_left(a, x)\n",
    "    if i != len(a):\n",
    "        return a[i]\n",
    "    raise ValueError\n",
    "    \n",
    "def find_frags_in_range(a, x, y):  \n",
    "    i = bisect.bisect_left(a, x)\n",
    "    j = bisect.bisect_right(a,y)\n",
    "    return a[i:j]\n",
    "\n",
    "def find_randomfrags_in_spec(fraglist, id): \n",
    "    indices = [i for i, x in enumerate(fraglist) if x.spectrum_id == id]\n",
    "    frags = [fraglist[i] for i in indices]\n",
    "    randomfrags = random.sample(frags, 5)\n",
    "    return randomfrags\n",
    "    \n",
    "    \n",
    "    \n",
    "   # indices = [i for i, x in enumerate(fraglist) if x.spectrum_id == id]\n",
    "   # print(\"Indices are: \", indices)\n",
    "   #  print(type(indices[0]))\n",
    "   # print(type(indices[2]))\n",
    "   # fragments = fraglist[indices] frags = operator.itemgetter(*fraglist)(indices)\n",
    "   # randomfragments = random.sample(fragments, 5)\n",
    "   # return randomfragments\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_fragments_list = []\n",
    "\n",
    "j = 0;\n",
    "\n",
    "for spec in library_spectrums :\n",
    "    i = 0;\n",
    "    for p in spec.peaks.mz:\n",
    "        frag = fragment_peak(spec.peaks.mz[i], spec.peaks.intensities[i], spec.get('spectrum_id'))\n",
    "        i += 1\n",
    "        All_fragments_list.append(frag)  \n",
    "    print(\"Full spectrum turned to \", i, \" fragments \")\n",
    "    print(len(All_fragments_list), \" frags in list\")\n",
    "    print(j, \" of \", len(library_spectrums), \" spectrums turned to fragment objects.\")\n",
    "    j += 1   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unsorted fragments lists:\")\n",
    "\n",
    "for i in range(20):\n",
    "    All_fragments_list[i].print_fragment()\n",
    "    \n",
    "all_fragments_list_sorted = sorted(All_fragments_list)\n",
    "\n",
    "print(\"Sorted by MZs: \")\n",
    "\n",
    "for i in range(20):\n",
    "    all_fragments_list_sorted[i].print_fragment()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_peaks = [len(spec.peaks) for spec in spectrums]\n",
    "\n",
    "print(spectrums[1].peaks.intensities)\n",
    "print(spectrums[2].peaks.intensities)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "hist = plt.hist(number_of_peaks, np.arange(0,2000,20))\n",
    "plt.xlabel(\"number of peaks in spectrum\")\n",
    "plt.ylabel(\"number of spectra in respective bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Decoy Approach\n",
    "\n",
    "For the naive decoy spectral library, we use all possible fragment ions from the reference library of spectra and then randomly add these ions to the decoy spectra library, until each decoy spectrum reaches the desired number of fragment ions that mimics the corresponding library spectrum. This method is presented as a baseline evaluation of the other, more intricate methods.\n",
    "\n",
    "1. Determine if there is a parent peak in target spectrum\n",
    "2. If parent peak = false, move to next spectrum in target spectra list.\n",
    "3. If parent peak = true, add to new decoy object:\n",
    "   - The parent peak is added to the array of peaks in the new decoy object\n",
    "4. Find number of peaks in target spectrum (the length of the list containing all peaks)\n",
    "5. Select that number of spectra randomly from the list of all spectra in target list\n",
    "6. Select from each of those individually a random peak\n",
    "7. Add those peaks to the list of peaks in the decoy spectrum, until number peaks in decoy spectrum = number of peaks in target spectrum. \n",
    "8. Add new complete decoy spectrum to decoy spectra library (naive)\n",
    "\n",
    "\n",
    "\n",
    "public Peak getParentPeak(Spectrum s) {\n",
    "        Peak parentpeak;\n",
    "        ArrayList<Peak> candidatepeaks = new ArrayList<Peak>;\n",
    "        Peak p = s.getPrecursor;\n",
    "        for(Peak counterpeak : s.getPeaks()) {\n",
    "            if(counterpeak.getMass >= p.getMass - 5 && counterpeak.getMass <= p.getMass + 5) {\n",
    "               candidatepeaks.add(counterpeak);\n",
    "               }\n",
    "            }  \n",
    "         if(candidatepeaks.size() == 0) {\n",
    "            system.out.print(\"No parent peak found\")\n",
    "                                                                                      \n",
    "            }\n",
    "         else {                                                                   \n",
    "               for(Peak p : candidatepeaks) {\n",
    "                  if(p.getIntensity() > parentpeak.getIntensity()) {\n",
    "                     parentpeak = p\n",
    "                    }\n",
    "         return parentpeak; \n",
    "    \n",
    "  \n",
    "    \n",
    "                                                                                    \n",
    "                                                                                  \n",
    " public spectrum createDecoy(Spectrum s) {  \n",
    "         parent = getParentPeak(s);\n",
    "         if(parent == none) {\n",
    "                system.out.print(\"No parent peak detected: decoy not created.\")\n",
    "                return null;\n",
    "                 }\n",
    "         else {\n",
    "                 Spectrum decoy = new Spectrum();\n",
    "                 decoy.peaks.addPeak(parent);\n",
    "                 Int peaksrequired = s.peaks.size() - 1;\n",
    "                 for(int i = 0; i < peaksrequired; i++) {\n",
    "                     ArrayList<Peak> possiblepeaks = new ArrayList<Peak>;                             \n",
    "                     Random r = new Random() (range 0 to spectrums.size());\n",
    "                     possiblepeaks = spectrums(r).getPeaks();\n",
    "                     Random r2 = new Random() (range 0 to possiblepeaks.size());\n",
    "                     decoy.peaks.addPeak(possiblepeaks(r2));\n",
    "                    }\n",
    "                  return decoy; \n",
    "                     \n",
    "                     \n",
    "              \n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.Spikes import Spikes\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def get_spectrum_info(s):\n",
    "    print(s.peaks.mz)\n",
    "    precursor = s.metadata['precursor_mz']\n",
    "    print(\"Precursor spectrum is: \", precursor)\n",
    "    print(\"Number of  peaks in spectrum is: \", len(s.peaks) )\n",
    "    masses = s.peaks.mz\n",
    "    print(masses)\n",
    "    print(s.peaks.intensities)     \n",
    "    mz = s.peaks.mz\n",
    "    intensities = s.peaks.intensities\n",
    "    print(intensities)\n",
    "    s.plot()\n",
    "\n",
    "\n",
    "def ispeakhere(s, precursor): \n",
    "    tolerance = (precursor / 1000000) * 5\n",
    "    return np.any((s.peaks.mz >= precursor - 5) & (s.peaks.mz <= precursor + 5))                                         \n",
    "\n",
    "\n",
    "def masswithin5ppm(m,range):\n",
    "    ishere = 0\n",
    "    tolerance = (m / 1000000) * 5\n",
    "    for r in range:\n",
    "        if m >= r - tolerance and m <= r + tolerance:\n",
    "            ishere = 1\n",
    "            break\n",
    "    return ishere\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_decoy_spectrums = []\n",
    "\n",
    "\n",
    "\n",
    "def create_naive_decoy(s):\n",
    "    print(get_parent_peak(s))\n",
    "    decoy_mz = np.array([get_parent_peak(s)[0]])\n",
    "    decoy_intensity = np.array([get_parent_peak(s)[1]])                        \n",
    "    peaks_in_target = len(s.peaks.mz)\n",
    "\n",
    "    random_spectrums = random.sample(library_spectrums, peaks_in_target - 1)\n",
    "\n",
    "    for spec in random_spectrums:\n",
    "        randommass =  random.choice(spec.peaks.mz)\n",
    "        index = np.where(spec.peaks.mz == randommass)\n",
    "        randomintensity = spec.peaks.intensities[index]\n",
    "        decoy_mz = np.append(decoy_mz, [randommass])\n",
    "        decoy_intensity = np.append(decoy_intensity, [randomintensity])\n",
    "        \n",
    "\n",
    "\n",
    "    decoy_mz = np.asarray(decoy_mz, dtype=float) \n",
    "    decoy_intensity = np.asarray(decoy_intensity, dtype=float) \n",
    "\n",
    "    inds  = decoy_mz.argsort()\n",
    "\n",
    "    sorted_intensities = decoy_intensity[inds]\n",
    "    sorted_mzs = decoy_mz[inds]\n",
    "\n",
    "    decoy = Spectrum(sorted_mzs, sorted_intensities) \n",
    "\n",
    "    naive_decoy_spectrums.append(decoy)\n",
    "       \n",
    "\n",
    "                            \n",
    "print( \"Total processed peaks = \", len(naive_decoy_spectrums))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for spec in library_spectrums:\n",
    "    create_naive_decoy(spec)\n",
    "    print(i, \" naive decoy created\")\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print( \"Total processed peaks = \", len(naive_decoy_spectrums))\n",
    "\n",
    "# print(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum-based Decoy Approach\n",
    "\n",
    "The second method is similar to the naive method, as we create the decoy spectral library through choosing fragment ions that co-appear in the spectra from the target spectral library (Fig. 1c): In this spectrum-based approach, we start with an empty set of fragment ion candidates. First, the precursor fragment ion of the target spectrum is added to the decoy spectrum. For each fragment ion added to the decoy spectrum, we choose all spectra from the target spectral library which contain this fragment ion, within a mass range of 5 p.p.m. From these spectra, we uniformly draw (all fragment ions have the same probability to be drawn) five fragment ions that are added to the fragment ion candidate set; we use all fragment ions in case there are fewer than five. We draw a fragment ion from the fragment ion candidate set and add it to the decoy spectrum, then proceed as described above until we reach the desired number of fragment ions that mimics the corresponding library spectrum. The two-step process of first drawing candidates, then drawing the actual decoy spectrum was introduced to better mimic fragmentation cascades and dependencies between fragments. Furthermore, it prevents that fragment-rich spectra dominate the process. Out of the five added candidate fragment ions, between zero and five end up in the final decoy spectrum. Fragment ions with mass close (5 p.p.m.) to a previously added fragment ion mass, or masses above the precursor fragment ion mass are discarded. If the precursor ion is absent from the MS/MS spectrum, we use the selected ion mass to find matching compound masses. \n",
    "\n",
    "1. Determine if there is a parent peak in target spectrum\n",
    "2. If parent peak = false, move to next spectrum in target spectra list.\n",
    "3. If parent peak = true, add to new decoy spectrum object:\n",
    "   - The parent peak is added to the array of peaks in the new decoy object\n",
    "4. Create a list of all spectra from the target list that contain the same fragment ion (search all peaks for a mass identical to or within a close range of the parent peak - mass range of 5 p.p.m)\n",
    "5. Create an empty list of candidate fragment ions that will be drawn from\n",
    "6. Draw 5 fragment ions from each of the spectra on list created at step 4 and add those to candidate list created at step 5\n",
    "7. Randomly draw a fragment ion from the candidate list:\n",
    "   - If its mass < precursor peak of target spectrum AND is not within 5 p.p.m of any other peak, then the peak is added to the      decoy spectrum's list of peaks.\n",
    "   - If it fails either of the conditions above, it is discarded and another candidate fragment is drawn.\n",
    "8. Repeat step 4- 7 until number peaks in decoy spectrum = number of peaks in target spectrum. \n",
    "9. Add completed decoy to decoy spectral library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_5_peaks(spectrum_id):\n",
    "    frag_list =[x for x in All_fragments_list if x.spectrum_id == spectrum_id]\n",
    "    frag_list = random.sample(frag_list, 5)\n",
    "    return frag_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrums_with_peak(mz):\n",
    "    tolerance = (mz / 1000000) * 5\n",
    "    x = fragment_peak(mz - tolerance, 0, 'counter')\n",
    "    y = fragment_peak(mz + tolerance, 0, 'counter2')\n",
    "    x = find_ge(all_fragments_list_sorted, x)\n",
    "    y = find_le(all_fragments_list_sorted, y)\n",
    "    \n",
    "   # print(\"Mass for search is:\", mz)\n",
    "    \n",
    "    first_frags = find_frags_in_range(all_fragments_list_sorted, x, y)\n",
    "    \n",
    "    # print(\"In first frags there are: \", len(first_frags), \"there masses are \")   \n",
    "\n",
    "    # for f in first_frags:\n",
    "     #   print(f.mz)\n",
    "        \n",
    "  #  print(\"Now retrieving spectrums:\")\n",
    "        \n",
    "    first_spectrum_ids = [f.spectrum_id for f in first_frags]\n",
    "    \n",
    "   # print(\"unsorted spectrum ids: \", len(first_spectrum_ids))\n",
    "    \n",
    "    final_spectrum_ids = list(dict.fromkeys(first_spectrum_ids))\n",
    "    \n",
    "    if(len(final_spectrum_ids) > 25):\n",
    "        final_spectrum_ids = random.sample(final_spectrum_ids, 25)\n",
    "        print(\"Too large: random sampled 25\")\n",
    "    \n",
    "    \n",
    "    #print(\"de-duplicated spectrum ids\", len(final_spectrum_ids))\n",
    "    \n",
    "          \n",
    "    return final_spectrum_ids\n",
    "\n",
    "\n",
    "\n",
    "def return_random_pick(candidatefrags,decoypeaks, parentmass):\n",
    "    \n",
    "   # print(\"Number of candidates on arrival: \", len(candidatefrags)) \n",
    "    candidatefrags = [x for x in candidatefrags if x.mz < parentmass] \n",
    "    \n",
    "   #  print(\"Number of candidates after those under parent peak thrown:\", len(candidatefrags))\n",
    "    \n",
    "    candidatefrags2 =[ x for x in candidatefrags if masswithin5ppm(x.mz, decoypeaks) == 0]\n",
    " \n",
    "    \n",
    "    try:\n",
    "        candidateion = random.choice(candidatefrags2)\n",
    "        \n",
    "    except: \n",
    "        candidateion = random.choice(candidatefrags)\n",
    "           \n",
    "    return candidateion\n",
    "          \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_spectrum_based_decoy_bisect(s):\n",
    "   # print(\"This spectrum has: \", len(s.peaks.mz), \" peaks.\")\n",
    "    parentmass = get_parent_peak(s)[0]\n",
    "    parentintensity = get_parent_peak(s)[1]\n",
    "    decoy_mz = np.array([parentmass])\n",
    "    decoy_intensities = np.array([parentintensity])\n",
    "   # print(\"Parent peak equals: \", parentmass, \"m/z, with intensity: \", parentintensity)\n",
    "    peaks_in_target = len(s.peaks.mz)  \n",
    "\n",
    "    candidate_fragments_list = []\n",
    "    \n",
    "    mass_for_loop_seeding = parentmass.copy()\n",
    "    \n",
    "    while(len(decoy_mz) < len(s.peaks.mz)):\n",
    "    \n",
    "        id_list = get_spectrums_with_peak(mass_for_loop_seeding)\n",
    "\n",
    "        for id in id_list:\n",
    "            random_peaks = random_sample_5_peaks(id)\n",
    "            candidate_fragments_list.extend(random_peaks)\n",
    "            \n",
    "        print(\"Length of candidate frags list: \", len(candidate_fragments_list))\n",
    "\n",
    "        drawn_ion = return_random_pick(candidate_fragments_list, decoy_mz, parentmass)\n",
    "\n",
    "        print(\"Drew randomly:\", drawn_ion.mz)\n",
    "        \n",
    "    \n",
    "\n",
    "        decoy_mz = np.append(decoy_mz, drawn_ion.mz)\n",
    "        decoy_intensities = np.append(decoy_intensities, drawn_ion.intensity)\n",
    "        \n",
    "        \n",
    "        print(\"Added peak with mass \", drawn_ion.mz, \"and intensity \", drawn_ion.intensity)\n",
    "        print(\"Decoy mz is length \", len(decoy_mz))\n",
    "        \n",
    "        mass_for_loop_seeding = drawn_ion.mz\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"Decoy masses has this number: \", len(decoy_mz))\n",
    "    print(\"Decoy intensities has this number: \", len(decoy_intensities)) \n",
    "\n",
    "                \n",
    "    decoy_mz = np.asarray(decoy_mz, dtype=float) \n",
    "    decoy_intensities = np.asarray(decoy_intensities, dtype=float) \n",
    "    inds  = decoy_mz.argsort()\n",
    "\n",
    "    sorted_intensities = decoy_intensities[inds]\n",
    "    sorted_masses = decoy_mz[inds]\n",
    "\n",
    "    decoy = Spectrum(sorted_masses, sorted_intensities) \n",
    "    \n",
    "\n",
    "    complex_decoy_spectrums.append(decoy)\n",
    "\n",
    "     \n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "decoyscreated = 1\n",
    "\n",
    "times_taken = []\n",
    "\n",
    "complex_decoy_spectrums = []\n",
    "\n",
    "\n",
    "for spec in library_spectrums:\n",
    "    start = time.time()\n",
    "    create_spectrum_based_decoy_bisect(spec)\n",
    "    end = time.time()\n",
    "    print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "    print(\" Decoy\", decoyscreated, \"of\", len(library_spectrums), \"created. Took \", end - start, \"to do.\")\n",
    "    print(\"------------------------------------------------------------------------------------------------------\")\n",
    "    decoyscreated += 1\n",
    "    end = time.time()\n",
    "    timetaken = end-start\n",
    "    times_taken.append(timetaken)\n",
    "    print(\"Time for decoy with\", len(spec.peaks.mz), \" peaks: \", timetaken)\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.exporting import save_as_mgf\n",
    "\n",
    "\n",
    "np.save('library_spectrums_21August', library_spectrums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.similarity import CosineGreedy\n",
    "\n",
    "class CosineHit:   \n",
    "    score = 0\n",
    "    type = None\n",
    "    query = None\n",
    "    library = None\n",
    "    qvalue = None\n",
    "    \n",
    "    def __init__(self, score, type, query, library):\n",
    "        self.score = score\n",
    "        self.type = type\n",
    "        self.query = query\n",
    "        self.library =library\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.score < other.score\n",
    "\n",
    "    def _eq_(self, other):\n",
    "        return self.score == other.score\n",
    "    \n",
    "    def getQuery(self):\n",
    "        return self.query\n",
    "    \n",
    "    def getLibrary(self):\n",
    "        return self.library\n",
    "    \n",
    "    def getQvalue(self):\n",
    "        return self.qvalue\n",
    "    \n",
    "    def setValue(self, q):\n",
    "        self.qvalue = q\n",
    "        \n",
    "    def setType(Self, type):\n",
    "        self.type = type\n",
    "\n",
    "def plot_hits(cosine_hits):\n",
    "    \n",
    "    scores = [score in cosine_hit in cosine_hits] \n",
    "    plt.figure(figsize=(12,7))\n",
    "    hist = plt.hist(scores, np.arange(0,1, 0.05))\n",
    "    plt.xlabel(\"cosine score of matches\")\n",
    "    plt.ylabel(\"number of queries in respective bin\")\n",
    "\n",
    "\n",
    "\n",
    "def return_list_cosine_scores(query, library, librarytype):\n",
    "         \n",
    "        if(librarytype != \"library\" and librarytype != \"decoy\"):\n",
    "            print(\"library type paramter must be either target or decoy\")\n",
    "            return False\n",
    "        else: \n",
    "            cosine_greedy = CosineGreedy(tolerance=0.2)\n",
    "            counter = 1\n",
    "            scores = []\n",
    "            average_matches = 0\n",
    "            milestone = 1\n",
    "            \n",
    "            if(librarytype == \"decoy\"):        \n",
    "                for spec in query:\n",
    "                    prelim_scores = []\n",
    "                    for d in library:\n",
    "                        score, n_matches = cosine_greedy(d, spec)\n",
    "                        average_matches = average_matches + n_matches\n",
    "                        newscore = CosineHit(score, librarytype, spec, d)\n",
    "                        prelim_scores.append(newscore)          \n",
    "\n",
    "                    prelim_scores = sorted(prelim_scores)\n",
    "                    scores.append(prelim_scores[-1])\n",
    "                    print(milestone)\n",
    "                    milestone += 1\n",
    "                    \n",
    "            if(librarytype == \"library\"):\n",
    "                for spec in query:\n",
    "                    prelim_scores = []\n",
    "                    for d in library:\n",
    "                        if(are_peaks_similar(spec.metadata['precursor_mz'], d.metadata['precursor_mz']) == True):\n",
    "                            score, n_matches = cosine_greedy(d, spec)\n",
    "                            average_matches = average_matches + n_matches\n",
    "                            newscore = CosineHit(score, librarytype, spec, d)\n",
    "                            prelim_scores.append(newscore)          \n",
    "\n",
    "                    prelim_scores = sorted(prelim_scores)\n",
    "                    scores.append(prelim_scores[-1])\n",
    "                    print(milestone)\n",
    "                    milestone += 1\n",
    "\n",
    "            return scores\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_library = return_list_cosine_scores(query_spectrums, library_spectrums, \"library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scores_library))\n",
    "\n",
    "for score in scores_library[-20:]:\n",
    "    print(score.score)\n",
    "    print(score.query.metadata['inchi'], score.library.metadata['inchi'])\n",
    "\n",
    "scores_library_sorted = sorted(scores_library)\n",
    "\n",
    "for score in scores_library_sorted[-20:]:\n",
    "    print(score.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_complex = return_list_cosine_scores(query_spectrums, complex_decoy_spectrums, \"decoy\")\n",
    "scores_naive= return_list_cosine_scores(query_spectrums, naive_decoy_spectrums, \"decoy\")\n",
    "\n",
    "print(len(scores_complex))\n",
    "\n",
    "for score in scores_complex[-20:]:\n",
    "    print(score.score)\n",
    "\n",
    "scores_complex_decoys_sorted = sorted(scores_complex)\n",
    "scores_naive_decoys_sorted = sorted(scores_naive)\n",
    "\n",
    "for score in scores_complex_decoys_sorted[-20:]:\n",
    "    print(score.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_fdr_list_decoys(sorted_scores): \n",
    "    fdr_at_index = []\n",
    "    for score in sorted_scores:\n",
    "        list_to_consider = [x for x in sorted_scores if x.score >= score.score]\n",
    "        decoy_hits_in_list = 0\n",
    "        library_hits_in_list = 0\n",
    "        for s in list_to_consider:     \n",
    "            if(s.spectrumtype == \"library\"):\n",
    "                library_hits_in_list += 1\n",
    "            else:\n",
    "                decoy_hits_in_list +=1\n",
    "        fdr = decoy_hits_in_list / library_hits_in_list\n",
    "        fdr_at_index.append(fdr)\n",
    "    \n",
    "    print(fdr_at_index)\n",
    "    return fdr_at_index\n",
    "\n",
    "def create_fdr_list_for_trues(sorted_scores):   \n",
    "    fdr_at_index = []\n",
    "    for score in sorted_scores:\n",
    "        list_to_consider = [x for x in sorted_scores if x.score >= score.score]\n",
    "        false_hits_in_list = 0\n",
    "        true_hits_in_list = 0\n",
    "        for s in list_to_consider:     \n",
    "            if(find_chem_string(s.getQuery()) == find_chem_string(s.getLibrary())):\n",
    "                true_hits_in_list += 1\n",
    "            else:\n",
    "                false_hits_in_list +=1             \n",
    "        fdr = false_hits_in_list / true_hits_in_list\n",
    "        fdr_at_index.append(fdr)\n",
    "        print(\"Found fdr \", fdr, \"for score \", score.score)\n",
    "        \n",
    "    return fdr_at_index\n",
    "\n",
    "\n",
    "def enumerate_reversed(seq):\n",
    "    n = len(seq)\n",
    "    for obj in reversed(seq):\n",
    "        n -= 1\n",
    "        yield n, obj\n",
    "\n",
    "def create_q_values_from_fdr_list(fdrlist, scores):\n",
    "    print(len(fdrlist))\n",
    "    for num, score in enumerate_reversed(scores):\n",
    "        if(score.spectrumtype == \"library\") or (score.spectrumtype == \"true\"):\n",
    "            print(num)\n",
    "            if(num == 1999):\n",
    "                qvalue = fdrlist[-1]\n",
    "            else: \n",
    "                list_of_fdr_to_consider = fdrlist[ 0 : num]\n",
    "                qvalue = min(list_of_fdr_to_consider)   \n",
    "                print(\"For score\", score.score, \" qvalue is: \", qvalue )\n",
    "            score.setValue(qvalue)\n",
    "                      \n",
    "    scores_to_return = [x for x in scores if x.spectrumtype == \"library\"] \n",
    "    return scores_to_return\n",
    "\n",
    "def create_q_values_from_fdr_list_true(fdrlist, scores):\n",
    "    print(len(fdrlist))\n",
    "    for num, score in enumerate_reversed(scores):\n",
    "        if(find_chem_string(score.getQuery()) == find_chem_string(score.getLibrary())):\n",
    "            print(num)\n",
    "            if(num == len(fdrlist) -1):\n",
    "                qvalue = fdrlist[-1]\n",
    "            else: \n",
    "                list_of_fdr_to_consider = fdrlist[ 0 : num]\n",
    "                qvalue = min(list_of_fdr_to_consider)   \n",
    "                print(\"For score\", score.score, \" qvalue is: \", qvalue )\n",
    "            score.setValue(qvalue)\n",
    "                      \n",
    "    scores_to_return = [x for x in scores if x.spectrumtype == \"library\"] \n",
    "    return scores_to_return\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_complex_merged = scores_library + scores_complex\n",
    "scores_complex_merged = sorted(scores_complex_merged)\n",
    "scores_complex_fdr_list = create_fdr_list_decoys(scores_complex_merged)\n",
    "print(len(scores_complex_fdr_list))\n",
    "complex_q_values = create_q_values_from_fdr_list(scores_complex_fdr_list, scores_complex_merged)\n",
    "print(len(complex_q_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores_fdr_list = create_fdr_list_for_trues(scores_library)\n",
    "print(true_scores_fdr_list)\n",
    "true_qvalues = create_q_values_from_fdr_list_true(true_scores_fdr_list, scores_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truescores = []\n",
    "falsescores = []\n",
    "\n",
    "for score in scores_library:\n",
    "    if(find_chem_string(score.getQuery()) == find_chem_string(score.getLibrary())):\n",
    "        truescores.append(score)\n",
    "    else:\n",
    "        falsescores.append(score)\n",
    "        \n",
    "        \n",
    "plottrues = []\n",
    "plotfalses = []\n",
    "\n",
    "for s in truescores:\n",
    "    plottrues.append(s.score)\n",
    "    \n",
    "for s in falsescores:\n",
    "    plotfalses.append(s.score)\n",
    "\n",
    "\n",
    "print(len(scores_library))\n",
    "print(len(plottrues))\n",
    "print(len(plotfalses))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "hist = plt.hist(plotfalses, np.arange(0,1,0.05))\n",
    "plt.xlabel(\"cosine score of scores\")\n",
    "plt.ylabel(\"number of scores in respective bin\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvalues_true = []\n",
    "\n",
    "qvalues_complex_estimate = []\n",
    "\n",
    "qvalues_naive_estimate = []\n",
    "\n",
    "for s in qvalues_library:\n",
    "    qvalues_true.append(s.qvalue)\n",
    "        \n",
    "for s in qvalue_estimates_complex_decoys:\n",
    "    qvalues_complex_estimate.append(s.qvalue)\n",
    "        \n",
    "for s in qvalue_estimates_naive_decoys: \n",
    "    qvalues_naive_estimate.append(s.qvalue)\n",
    "        \n",
    "        \n",
    "print(len(qvalues_true))\n",
    "\n",
    "print(len(qvalues_complex_estimate))\n",
    "\n",
    "print(len(qvalues_naive_estimate))\n",
    "    \n",
    "          \n",
    "plt.figure(figsize=(17,7))\n",
    "plt.title(\"title\")\n",
    "plt.xlabel( 'True Qvalues')\n",
    "plt.ylabel('Estimated Qvalues')\n",
    "plt.plot(qvalues_complex_estimate, qvalues_true, 'rx', label = \"Spectrum-Based Decoys\")\n",
    "plt.plot(qvalues_naive_estimate, qvalues_true, 'bx', label = \"Naive Decoys\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
