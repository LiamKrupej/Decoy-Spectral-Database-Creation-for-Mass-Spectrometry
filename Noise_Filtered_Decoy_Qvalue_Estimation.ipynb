{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import random\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import custom_filtering\n",
    "import molmass\n",
    "import mass_spec_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from matchms import Scores, Spectrum\n",
    "from matchms.importing import load_from_json\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "#path_data = os.path.join(ROOT, 'data')\n",
    "path_data = 'C:\\\\Users\\\\User\\\\Data'\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "from matchms.importing import load_from_json\n",
    "\n",
    "filename = os.path.join(path_data,'gnps_positive_ionmode_cleaned_by_matchms_and_lookups.json')\n",
    "spectrums = load_from_json(filename)\n",
    "\n",
    "print(\"number of spectra:\", len(spectrums))\n",
    "\n",
    "number_of_peaks = [len(spec.peaks) for spec in spectrums]\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "hist = plt.hist(number_of_peaks, np.arange(0,2000,20))\n",
    "plt.xlabel(\"number of peaks in spectrum\")\n",
    "plt.ylabel(\"number of spectra in respective bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "\n",
    "\n",
    "def post_process(s):\n",
    "    s = normalize_intensities(s)\n",
    "    s = select_by_mz(s, mz_from=0, mz_to=1000)\n",
    "    s = select_by_relative_intensity(s, intensity_from=0.01, intensity_to=1.0)\n",
    "    s = reduce_to_number_of_peaks(s, 10, 1000, None)\n",
    "    return s\n",
    "\n",
    "# apply filters to the data\n",
    "spectrums = [post_process(s) for s in spectrums]\n",
    "\n",
    "# omit spectrums that didn't qualify for analysis\n",
    "spectrums = [s for s in spectrums if s is not None]\n",
    "\n",
    "spectrumswithpeak = []\n",
    "\n",
    "from custom_filtering import get_parent_peak\n",
    "\n",
    "for spec in spectrums:\n",
    "    if(get_parent_peak(spec) is not None):\n",
    "        spectrumswithpeak.append(spec)\n",
    "    \n",
    "print(len(spectrumswithpeak))\n",
    "\n",
    "from custom_filtering import find_chem_string\n",
    "\n",
    "\n",
    "spectrums_with_inchi = []\n",
    "\n",
    "for spec in spectrumswithpeak:\n",
    "    if(find_chem_string(spec) is not None) and (type(spec.metadata['adduct']) is str):\n",
    "        spectrums_with_inchi.append(spec)\n",
    "         \n",
    "positive_adducts = []\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(r'C:\\Users\\User\\Data\\positive_adducts.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        row = ', '.join(row)\n",
    "        positive_adducts.append(row)\n",
    "        \n",
    "spectrums_processed = []\n",
    "\n",
    "for spec in spectrums_with_inchi:\n",
    "    if(spec.metadata['adduct'] in positive_adducts):\n",
    "        spectrums_processed.append(spec)\n",
    "\n",
    "print(len(spectrums_processed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "json_data = []\n",
    "a = glob.glob(r'C:\\\\Users\\\\User\\\\Data\\\\Filtering_Data\\\\trees\\\\*.json', recursive=True)\n",
    "\n",
    "for filename in a:\n",
    "    with open(filename,'r') as f:\n",
    "        json_data.append(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_data[1].keys())\n",
    "\n",
    "chem_formulas = []\n",
    "\n",
    "for mol in json_data:\n",
    "    for frag in mol.get('fragments'):\n",
    "        chem_formulas.append(frag.get('molecularFormula'))\n",
    "        \n",
    "print(len(chem_formulas))\n",
    "\n",
    "unique_chem_formulas = []\n",
    "\n",
    "for chem in chem_formulas:\n",
    "    if(chem not in unique_chem_formulas) & (chem != \"\"):\n",
    "        unique_chem_formulas.append(chem)\n",
    "        \n",
    "print(len(unique_chem_formulas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adducts = []\n",
    "\n",
    "for spec in spectrums_processed:\n",
    "    if(spec.metadata['adduct'] not in adducts):\n",
    "        adducts.append(spec.metadata['adduct'])\n",
    "        \n",
    "from molmass import Formula\n",
    "\n",
    "print(adducts)\n",
    "\n",
    "f = Formula(unique_chem_formulas[0])\n",
    "\n",
    "print(\"For chem formula \", f.formula, \" mass is \", f.mass)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrums_processed[0].peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from noise_filtering import AdductAndMassLibrary\n",
    "\n",
    "AML = AdductAndMassLibrary(adducts, unique_chem_formulas)\n",
    "\n",
    "from matchms.similarity import CosineGreedy\n",
    "\n",
    "noise_filtered_spectrums = []\n",
    "\n",
    "chucked_spectrums = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for spec in spectrums_processed:\n",
    "    spec1 = AML.return_noise_filtered_spectrum(spec)\n",
    "    if(len(spec1.peaks.mz) == 0):\n",
    "        chucked_spectrums.append(spec1)\n",
    "    else:\n",
    "        noise_filtered_spectrums.append(spec1)\n",
    "    print(counter)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "print(\"Processed: \", len(noise_filtered_spectrums), \" chucked: \", len(chucked_spectrums))\n",
    "\n",
    "cosine_greedy = CosineGreedy(tolerance = 0.2)\n",
    "\n",
    "print(cosine_greedy(spectrums_processed[1], spectrums_processed[1]))\n",
    "print(cosine_greedy(spectrums_processed[0], noise_filtered_spectrums[0]))\n",
    "\n",
    "spectrums_processed[0].plot()\n",
    "noise_filtered_spectrums[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_processed[0].plot()\n",
    "noise_filtered_spectrums[0].plot()\n",
    "print(spectrums_processed[0].peaks.mz)\n",
    "print(noise_filtered_spectrums[0].peaks.mz)\n",
    "print(cosine_greedy(spectrums_processed[0], noise_filtered_spectrums[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_processed[1].plot()\n",
    "noise_filtered_spectrums[1].plot()\n",
    "print(spectrums_processed[1].peaks.mz)\n",
    "print(noise_filtered_spectrums[1].peaks.mz)\n",
    "print(cosine_greedy(spectrums_processed[1], noise_filtered_spectrums[1]))\n",
    "\n",
    "spectrums = [] \n",
    "\n",
    "for spec in spectrums_processed:\n",
    "    if(len(spec.peaks.mz) < 6):\n",
    "        spectrums.append(spec)\n",
    "\n",
    "print(len(spectrums))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_spectrums = []\n",
    "query_spectrums = []\n",
    "\n",
    "from custom_filtering import is_molecule_here\n",
    "\n",
    "for spec in noise_filtered_spectrums:\n",
    "        if(len(library_spectrums) == 3000) & (len(query_spectrums) == 1000):\n",
    "            break   \n",
    "        if(is_molecule_here(spec, library_spectrums) == 0) & (len(library_spectrums) < 3000):\n",
    "            library_spectrums.append(spec)\n",
    "            print(\"library is \", len(library_spectrums), \"and query is \", len(query_spectrums))\n",
    "        else:\n",
    "            if(is_molecule_here(spec,query_spectrums) == 0) & (is_molecule_here(spec, library_spectrums) == 1) & (len(query_spectrums) < 1000):\n",
    "                query_spectrums.append(spec)\n",
    "                print(\"library is \", len(library_spectrums), \"and query is \", len(query_spectrums))\n",
    "\n",
    "        \n",
    "          \n",
    "print(len(library_spectrums))\n",
    "print(len(query_spectrums))\n",
    "\n",
    "\n",
    "molecule_matches = 0\n",
    "for spec in query_spectrums:\n",
    "    if(is_molecule_here(spec, library_spectrums) == 1):\n",
    "        molecule_matches += 1\n",
    "\n",
    "print(\"Molecule matches =\", molecule_matches)\n",
    "\n",
    "from custom_analysis import look_for_inchi_and_precursor\n",
    "\n",
    "look_for_inchi_and_precursor(query_spectrums, library_spectrums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_fragment import FragmentPeak\n",
    "\n",
    "all_fragments_list = []\n",
    "\n",
    "j = 0;\n",
    "\n",
    "for spec in library_spectrums:\n",
    "    i = 0;\n",
    "    for p in spec.peaks.mz:\n",
    "        frag = FragmentPeak(spec.peaks.mz[i], spec.peaks.intensities[i], spec.get('spectrum_id'))\n",
    "        i += 1\n",
    "        all_fragments_list.append(frag)  \n",
    "    print(\"Full spectrum turned to \", i, \" fragments \")\n",
    "    print(len(all_fragments_list), \" frags in list\")\n",
    "    print(j, \" of \", len(library_spectrums), \" spectrums turned to fragment objects.\")\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unsorted fragments lists:\")\n",
    "\n",
    "for i in range(20):\n",
    "    all_fragments_list[i].print_fragment()\n",
    "    \n",
    "all_fragments_list_sorted = sorted(all_fragments_list)\n",
    "\n",
    "print(\"Sorted by MZs: \")\n",
    "\n",
    "for i in range(20):\n",
    "    all_fragments_list_sorted[i].print_fragment()\n",
    "    \n",
    "number_of_peaks = [len(spec.peaks) for spec in spectrums]\n",
    "\n",
    "print(spectrums[1].peaks.intensities)\n",
    "print(spectrums[2].peaks.intensities)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "hist = plt.hist(number_of_peaks, np.arange(0,2000,20))\n",
    "plt.xlabel(\"number of peaks in spectrum\")\n",
    "plt.ylabel(\"number of spectra in respective bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoy_helpers import ispeakhere, masswithin5ppm\n",
    "import random\n",
    "\n",
    "def create_naive_decoy(s):\n",
    "    print(get_parent_peak(s))\n",
    "    decoy_mz = np.array([get_parent_peak(s)[0]])\n",
    "    decoy_intensity = np.array([get_parent_peak(s)[1]])                        \n",
    "    peaks_in_target = len(s.peaks.mz)\n",
    "\n",
    "    random_spectrums = random.sample(library_spectrums, peaks_in_target - 1)\n",
    "\n",
    "    for spec in random_spectrums:\n",
    "        randommass =  random.choice(spec.peaks.mz)\n",
    "        index = np.where(spec.peaks.mz == randommass)\n",
    "        randomintensity = spec.peaks.intensities[index]\n",
    "        decoy_mz = np.append(decoy_mz, [randommass])\n",
    "        decoy_intensity = np.append(decoy_intensity, [randomintensity])\n",
    "        \n",
    "\n",
    "\n",
    "    decoy_mz = np.asarray(decoy_mz, dtype=float) \n",
    "    decoy_intensity = np.asarray(decoy_intensity, dtype=float) \n",
    "\n",
    "    inds  = decoy_mz.argsort()\n",
    "\n",
    "    sorted_intensities = decoy_intensity[inds]\n",
    "    sorted_mzs = decoy_mz[inds]\n",
    "\n",
    "    decoy = Spectrum(sorted_mzs, sorted_intensities)\n",
    "    \n",
    "    return decoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "naive_decoy_spectrums = []\n",
    "\n",
    "for spec in library_spectrums:\n",
    "    s = create_naive_decoy(spec)\n",
    "    naive_decoy_spectrums.append(s)\n",
    "    print(i, \" naive decoy created\")\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print( \"Total processed peaks = \", len(naive_decoy_spectrums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoy_helpers import random_sample_5_peaks, get_spectrums_with_peak, return_random_pick\n",
    "import time\n",
    "\n",
    "def create_spectrum_based_decoy_bisect(s):\n",
    "    start = time.time()\n",
    "   # print(\"This spectrum has: \", len(s.peaks.mz), \" peaks.\")\n",
    "    parentmass = get_parent_peak(s)[0]\n",
    "    parentintensity = get_parent_peak(s)[1]\n",
    "    decoy_mz = np.array([parentmass])\n",
    "    decoy_intensities = np.array([parentintensity])\n",
    "   # print(\"Parent peak equals: \", parentmass, \"m/z, with intensity: \", parentintensity)\n",
    "    peaks_in_target = len(s.peaks.mz)  \n",
    "    candidate_fragments_list = []\n",
    "    mass_for_loop_seeding = parentmass.copy()\n",
    "    \n",
    "    while(len(decoy_mz) < len(s.peaks.mz)):\n",
    "    \n",
    "        id_list = get_spectrums_with_peak(mass_for_loop_seeding, all_fragments_list_sorted)\n",
    "\n",
    "        for id in id_list:\n",
    "            random_peaks = random_sample_5_peaks(id, all_fragments_list)\n",
    "            candidate_fragments_list.extend(random_peaks)\n",
    "            \n",
    "     #   print(\"Length of candidate frags list: \", len(candidate_fragments_list))\n",
    "        drawn_ion = return_random_pick(candidate_fragments_list, decoy_mz, parentmass)\n",
    "\n",
    "      #  print(\"Drew randomly:\", drawn_ion.mz)\n",
    "        decoy_mz = np.append(decoy_mz, drawn_ion.mz)\n",
    "        decoy_intensities = np.append(decoy_intensities, drawn_ion.intensity)\n",
    "        \n",
    "        \n",
    "     #   print(\"Added peak with mass \", drawn_ion.mz, \"and intensity \", drawn_ion.intensity)\n",
    "     #   print(\"Decoy mz is length \", len(decoy_mz))\n",
    "        \n",
    "        mass_for_loop_seeding = drawn_ion.mz       \n",
    "    \n",
    "   # print(\"Decoy masses has this number: \", len(decoy_mz))\n",
    "   # print(\"Decoy intensities has this number: \", len(decoy_intensities)) \n",
    "               \n",
    "    decoy_mz = np.asarray(decoy_mz, dtype=float) \n",
    "    decoy_intensities = np.asarray(decoy_intensities, dtype=float) \n",
    "    inds  = decoy_mz.argsort()\n",
    "    sorted_intensities = decoy_intensities[inds]\n",
    "    sorted_masses = decoy_mz[inds]\n",
    "    decoy = Spectrum(sorted_masses, sorted_intensities) \n",
    "    \n",
    "    end = time.time()\n",
    "    timetaken = end-start\n",
    "    times_taken.append(timetaken)\n",
    "    print(\"Time for decoy with\", len(spec.peaks.mz), \" peaks: \", timetaken)\n",
    "    print(numdecoys, \"of \", len(library_spectrums), \" created.\")\n",
    "    \n",
    "    return decoy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoyscreated = 1\n",
    "\n",
    "times_taken = []\n",
    "\n",
    "complex_decoy_spectrums = []\n",
    "\n",
    "create_spectrum_based_decoy_bisect(library_spectrums[176])\n",
    "\n",
    "failed_to_create = []\n",
    "\n",
    "\n",
    "for spec in library_spectrums:\n",
    "    start = time.time()\n",
    "    try:\n",
    "        create_spectrum_based_decoy_bisect(spec)\n",
    "    except:\n",
    "        failed_to_create.append(spec)\n",
    "        print(\"failed to create\")\n",
    "    end = time.time()\n",
    "    print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "    print(\" Decoy\", decoyscreated, \"of\", len(library_spectrums), \"created. Took \", end - start, \"to do.\")\n",
    "    print(\"------------------------------------------------------------------------------------------------------\")\n",
    "    decoyscreated += 1\n",
    "    end = time.time()\n",
    "    timetaken = end-start\n",
    "    times_taken.append(timetaken)\n",
    "    print(\"Time for decoy with\", len(spec.peaks.mz), \" peaks: \", timetaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (spec2vec_gnps_data_analysis)",
   "language": "python",
   "name": "pycharm-f13352e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
